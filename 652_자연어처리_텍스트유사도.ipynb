{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDmD1Nfk8PYAXmwCVr/Bk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onleey/Machine-Learning_demo/blob/master/652_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_%ED%85%8D%EC%8A%A4%ED%8A%B8%EC%9C%A0%EC%82%AC%EB%8F%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í…ìŠ¤íŠ¸ ìœ ì‚¬ë„\n",
        "- ì„ë² ë”©ìœ¼ë¡œ ê° ë‹¨ì–´ë“¤ì˜ ë²¡í„°ë¥¼ êµ¬í•œ ë‹¤ìŒ ë²¡í„° ê°„ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë‹¨ì–´ ê°„ì˜ ì˜ë¯¸ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤. ë¬¸ì¥ ì—­ì‹œ ë‹¨ì–´ë“¤ì˜ ë¬¶ìŒì´ê¸° ë•Œë¬¸ì— í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë¬¶ì–´ì„œ ë¬¸ì¥ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\n",
        "- ë‘ ë¬¸ì¥ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ë¬¸ì¥ ë‚´ì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ë“¤ì„ ìˆ˜ì¹˜í™”í•´ì•¼ í•œë‹¤.  ì´ë•Œ ì–¸ì–´ ëª¨ë¸ì— ë”°ë¼ í†µê³„ë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•ê³¼ ì¸ê³µ ì‹ ê²½ë§ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. Word2Vecì€ ì¸ê³µ ì‹ ê²½ë§ì„ ì´ìš©ì´ê³  n-gram ìœ ì‚¬ë„ì™€ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” í†µê³„ì ë°©ì‹ì´ë‹¤."
      ],
      "metadata": {
        "id": "3bFn3ve3COnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. n-gram ìœ ì‚¬ë„\n",
        "\n",
        "- n-gramì€ ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ nê°œì˜ ì—°ì†ì ì¸ ë‹¨ì–´ ì‹œí€€ìŠ¤(ë‹¨ì–´ ë‚˜ì—´)ë¥¼ ì˜ë¯¸í•œë‹¤. n-gramì€ ë¬¸ì¥ì—ì„œ nê°œì˜ ë‹¨ì–´ë¥¼ í† í°ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ì´ëŠ” ì´ì›ƒí•œ ë‹¨ì–´ì˜ ì¶œí˜„ íšŸìˆ˜ë¥¼ í†µê³„ì ìœ¼ë¡œ í‘œí˜„í•´ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì´ë‹¤.\n",
        "- ì„œë¡œ ë‹¤ë¥¸ ë¬¸ì¥ì„ n-gramìœ¼ë¡œ ë¹„êµí•˜ë©´ ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ì— ê¸°ë°˜í•œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ë…¼ë¬¸ ì¸ìš©ì´ë‚˜ ë„ìš© ì •ë„ë¥¼ ì¡°ì‚¬í•  ìˆ˜ ìˆë‹¤.\n",
        "- https://medium.com/@pankajchandravanshi/nlp-unlocked-n-grams-006-ceab1bc56bf4\n",
        "- nì´ 1ì¸ ê²½ìš° 1- gram ë˜ëŠ” ìœ ë‹ˆê·¸ë¨(unigram), 2ì¸ ê²½ìš° 2-gram ë˜ëŠ” ë°”ì´ê·¸ë¨(bigram), 3ì¸ ê²½ìš° 3-gram ë˜ëŠ” íŠ¸ë¼ì´ê·¸ë¨(trigram), 4ì´ìƒì€ ìˆ«ìë§Œ ì•ìª½ì— ë¶™ì—¬ ë¶€ë¥¸ë‹¤.\n",
        "- n-gram ìœ ì‚¬ë„  \n",
        "  similarity = $\\frac{tf(A,B)}{tokens(A)}$\n",
        "   - tf(term frequency)ëŠ” ë‘ ë¬¸ì¥ Aì™€ Bì—ì„œ ë™ì¼í•œ í† í°ì˜ ì¶œí˜„ ë¹ˆë„ë¥¼ ëœ»í•˜ë©°, tokensëŠ” í•´ë‹¹ ë¬¸ì¥ì—ì„œ ì „ì²´ í† í° ìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤. ì—¬ê¸°ì„œ í† í°ì´ë€ n-gramìœ¼ë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ì´ë‹¤. 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ Bê°€ Aì— ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.\n",
        "   - ë¬¸ì¥ Aì˜ 2-gram í† í°   \n",
        "   A : 6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ íŠ¸ë¦¬ë‹ˆí‹°ì— ì…í•™í–ˆë‹¤.   \n",
        "   B : 6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ ëŒ€í•™êµì— ì…í•™í–ˆë‹¤.    \n",
        "\n",
        "\n",
        "   | |(6ì›”,ë‰´í„´)|(ë‰´í„´,ì„ ìƒë‹˜)|(ì„ ìƒë‹˜,ì œì•ˆ)|(ì œì•ˆ,íŠ¸ë¦¬ë‹ˆí‹°)|(íŠ¸ë¦¬ë‹ˆí‹°,ì…í•™)|(ì…í•™)| | |\n",
        "   |---|---|---|---|---|---|---|---|---|\n",
        "   |A|1|1|1|1|1|1|6|=>toekns(A)|\n",
        "   |B|1|1|1|0|0|1|4|=>tf(A,B)|"
      ],
      "metadata": {
        "id": "67jLZRccCdlH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbafU52FBF6a",
        "outputId": "478bdfe7-e0b7-4dd1-c9ef-b902871afb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n-gram ìœ ì‚¬ë„"
      ],
      "metadata": {
        "id": "KQK6lezwDWGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "\n",
        "\n",
        "# ì–´ì ˆ ë‹¨ìœ„ n-gram\n",
        "def word_ngram(bow, num_gram):\n",
        "    text = tuple(bow)\n",
        "    ngrams = [text[x:x + num_gram] for x in range(0, len(text))]\n",
        "    return tuple(ngrams)\n",
        "\n",
        "\n",
        "# ìŒì ˆ n-gram ë¶„ì„\n",
        "def phoneme_ngram(bow, num_gram):\n",
        "    sentence = ' '.join(bow)\n",
        "    text = tuple(sentence)\n",
        "    slen = len(text)\n",
        "    ngrams = [text[x:x + num_gram] for x in range(0, slen)]\n",
        "    return ngrams\n",
        "\n",
        "\n",
        "# ìœ ì‚¬ë„ ê³„ì‚°\n",
        "def similarity(doc1, doc2):\n",
        "    cnt = 0\n",
        "    for token in doc1:\n",
        "        if token in doc2:\n",
        "            cnt = cnt + 1\n",
        "\n",
        "    return cnt/len(doc1)\n",
        "\n",
        "\n",
        "sentence1 = '6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ íŠ¸ë¦¬ë‹ˆí‹°ì— ì…í•™í•˜ì˜€ë‹¤'\n",
        "sentence2 = '6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ ëŒ€í•™êµì— ì…í•™í•˜ì˜€ë‹¤'\n",
        "sentence3 = 'ë‚˜ëŠ” ë§›ì‡ëŠ” ë°¥ì„ ë‰´í„´ ì„ ìƒë‹˜ê³¼ í•¨ê»˜ ë¨¹ì—ˆìŠµë‹ˆë‹¤.'\n",
        "\n",
        "komoran = Komoran()\n",
        "bow1 = komoran.nouns(sentence1)\n",
        "bow2 = komoran.nouns(sentence2)\n",
        "bow3 = komoran.nouns(sentence3)\n",
        "\n",
        "print(bow1)\n",
        "print(bow2)\n",
        "print(bow3)\n",
        "\n",
        "doc1 = word_ngram(bow1, 2)\n",
        "doc2 = word_ngram(bow2, 2)\n",
        "doc3 = word_ngram(bow3, 2)\n",
        "\n",
        "print(doc1)\n",
        "print(doc2)\n",
        "print(doc3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-LSuLCADGk_",
        "outputId": "6a7427e2-d49b-4f9b-e8a7-382f14aad466"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['6ì›”', 'ë‰´í„´', 'ì„ ìƒë‹˜', 'ì œì•ˆ', 'íŠ¸ë¦¬ë‹ˆí‹°', 'ì…í•™']\n",
            "['6ì›”', 'ë‰´í„´', 'ì„ ìƒë‹˜', 'ì œì•ˆ', 'ëŒ€í•™êµ', 'ì…í•™']\n",
            "['ë§›', 'ë°¥', 'ë‰´í„´', 'ì„ ìƒ', 'ë‹˜ê³¼ í•¨ê»˜']\n",
            "(('6ì›”', 'ë‰´í„´'), ('ë‰´í„´', 'ì„ ìƒë‹˜'), ('ì„ ìƒë‹˜', 'ì œì•ˆ'), ('ì œì•ˆ', 'íŠ¸ë¦¬ë‹ˆí‹°'), ('íŠ¸ë¦¬ë‹ˆí‹°', 'ì…í•™'), ('ì…í•™',))\n",
            "(('6ì›”', 'ë‰´í„´'), ('ë‰´í„´', 'ì„ ìƒë‹˜'), ('ì„ ìƒë‹˜', 'ì œì•ˆ'), ('ì œì•ˆ', 'ëŒ€í•™êµ'), ('ëŒ€í•™êµ', 'ì…í•™'), ('ì…í•™',))\n",
            "(('ë§›', 'ë°¥'), ('ë°¥', 'ë‰´í„´'), ('ë‰´í„´', 'ì„ ìƒ'), ('ì„ ìƒ', 'ë‹˜ê³¼ í•¨ê»˜'), ('ë‹˜ê³¼ í•¨ê»˜',))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "a = np.array([[1,2,3]])\n",
        "\n",
        "#í–‰ë ¬ê³±\n",
        "#print(dot(a,a))\n",
        "\n",
        "#í–‰ë ¬ë‚´ì \n",
        "print(a*a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-sXgWWvMj8Y",
        "outputId": "aba5c0e1-a9f0-4214-b4bb-4232fc7582ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
        "\n",
        "- ë‹¨ì–´ë‚˜ ë¬¸ì¥ì„ ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤ë©´ ë²¡í„° ê°„ ê±°ë¦¬ë‚˜ ê°ë„ë¥¼ ì´ìš©í•´ ìœ ì‚¬ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. ë²¡í„° ê°„ ê±°ë¦¬ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ë©° ì—¬ê¸°ì—ì„œëŠ” ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œë‹¤.\n",
        "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ê°ë„ë¥¼ ì´ìš©í•´ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì´ë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë²¡í„°ì˜ í¬ê¸°ê°€ ì¤‘ìš”í•˜ì§€ ì•Šì„ ë•Œ ê·¸ ê±°ë¦¬ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.\n",
        "- ë‹¨ì–´ì˜ ì¶œí˜„ ë¹ˆë„ë¥¼ í†µí•´ ìœ ì‚¬ë„ ê³„ì‚°ì„ í•œë‹¤ë©´ ë™ì¼í•œ ë‹¨ì–´ê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆì„ìˆ˜ë¡ ë²¡í„°ì˜ í¬ê¸°ê°€ ì»¤ì§„ë‹¤. ì´ë•Œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë²¡í„°ì˜ í¬ê¸°ì™€ ìƒê´€ì—†ì´ ê²°ê³¼ê°€ ì•ˆì •ì ì´ë‹¤.\n",
        "- n-gramì˜ ê²½ìš° ë™ì¼í•œ ë‹¨ì–´ê°€ ë¬¸ì„œ ë‚´ì— ìì£¼ ë“±ì¥í•˜ë©´ ìœ ì‚¬ë„ ê²°ê³¼ì— ì•ˆ ì¢‹ì€ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ë°–ì— ì—†ë‹¤. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‹¤ì–‘í•œ ì°¨ì›ì—ì„œ ì ìš© ê°€ëŠ¥í•´ ì‹¤ë¬´ì—ì„œ ë§ì´ ì‚¬ìš©í•œë‹¤.\n",
        "- ì½”ì‚¬ì¸ -1 ~ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, ë‘ ë²¡í„°ì˜ ë°©í–¥ì´ ì™„ì „íˆ ë™ì¼í•œ ê²½ìš°ì—ëŠ” 1, ë°˜ëŒ€ ë°©í–¥ì¸ ê²½ìš°ì—ëŠ” -1, ë‘ ë²¡í„°ê°€ ì„œë¡œ ì§ê°ì„ ì´ë£¨ë©´ 0ì˜ ê°’ì„ ê°€ì§„ë‹¤. ì¦‰, ë‘ ë²¡í„°ì˜ ë°©í–¥ì´ ê°™ì•„ ì§ˆìˆ˜ë¡ ìœ ì‚¬í•˜ë‹¤ ë³¼ ìˆ˜ ìˆë‹¤.\n",
        "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ê³µê°„ ë²¡í„°ì˜ ë‚´ì ê³¼ í¬ê¸°ë¥¼ ì´ìš©í•´ ì½”ì‚¬ì¸ ê°ë„ë¥¼ ê³„ì‚°í•œë‹¤.\n",
        "\n",
        "similarity = $\\cos$Î¸ = $\\frac{AÂ·B}{||A||||B||}$ = $\\frac{\\sum_{i=1}^{n}A_iğš‡  B_i}{\\sqrt{\\sum_{i=1}^{n}}(A_{i})^2 X \\sqrt{\\sum_{i=1}^{n}}(B_{i})^2}$\n",
        "\n",
        "\n",
        "A : 6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ íŠ¸ë¦¬ë‹ˆí‹°ì— ì…í•™í–ˆë‹¤.   \n",
        "   B : 6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ ëŒ€í•™êµì— ì…í•™í–ˆë‹¤.    \n",
        "\n",
        "\n",
        "   | |6ì›”|ë‰´í„´|ì„ ìƒë‹˜|ì œì•ˆ|íŠ¸ë¦¬ë‹ˆí‹°|ì…í•™|ëŒ€í•™ |\n",
        "   |---|---|---|---|---|---|---|---|\n",
        "   |A|1|1|1|1|1|1|0|\n",
        "   |B|1|1|1|1|0|1|1|\n",
        "\n",
        "\n",
        "   ${AÂ·B}$ = $\\sum_{i=1}^{n}A_i ğš‡  B_i$  \n",
        "            = (1*1) + (1*1)+ (1*1)+ (1*1)+ (1*0)+ (1*1)+ (0*1)  \n",
        "            = 1+1+1+1+0+1+0  \n",
        "            = 5  \n",
        "\n",
        "   \n",
        "  ${||A||||B||}$  = ${\\sqrt{\\sum_{i=1}^{n}}(A_{i})^2 X \\sqrt{\\sum_{i=1}^{n}}(B_{i})^2}$     \n",
        "= $\\sqrt {1^{2}+1^{2}+1^{2}+1^{2}+1^{2}+1^{2}+0^{2}} X \\sqrt {1^{2}+1^{2}+1^{2}+1^{2}+0^{2}+1^{2}+1^{2}}$    \n",
        "= $\\sqrt{6} X \\sqrt{6}$  \n",
        "= $\\sqrt{36}$  \n",
        "= 6  \n",
        "\n",
        "\n",
        "similarity = $\\cos$Î¸ = $\\frac{AÂ·B}{||A||||B||}$ = $\\frac{5}{6}$ = 0.83333"
      ],
      "metadata": {
        "id": "p_6oFZ5uPeHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "def cos_sim(vec1, vec2):\n",
        "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "\n",
        "# TDM ë§Œë“¤ê¸°\n",
        "def make_term_doc_mat(sentence_bow, word_dics):\n",
        "    freq_mat = {}\n",
        "\n",
        "    for word in word_dics:\n",
        "        freq_mat[word] = 0\n",
        "\n",
        "    for word in word_dics:\n",
        "        if word in sentence_bow:\n",
        "            freq_mat[word] += 1\n",
        "\n",
        "    return freq_mat"
      ],
      "metadata": {
        "id": "DgG30TuhSCeF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¨ì–´ ë²¡í„° ë§Œë“¤ê¸°\n",
        "def make_vector(tdm):\n",
        "    vec = []\n",
        "    for key in tdm:\n",
        "        vec.append(tdm[key])\n",
        "    return vec\n",
        "\n",
        "\n",
        "# ë¬¸ì¥ ì •ì˜\n",
        "sentence1 = '6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ íŠ¸ë¦¬ë‹ˆí‹°ì— ì…í•™í•˜ì˜€ë‹¤'\n",
        "sentence2 = '6ì›”ì— ë‰´í„´ì€ ì„ ìƒë‹˜ì˜ ì œì•ˆìœ¼ë¡œ ëŒ€í•™êµì— ì…í•™í•˜ì˜€ë‹¤'\n",
        "sentence3 = 'ë‚˜ëŠ” ë§›ì‡ëŠ” ë°¥ì„ ë‰´í„´ ì„ ìƒë‹˜ê³¼ í•¨ê»˜ ë¨¹ì—ˆìŠµë‹ˆë‹¤.'\n",
        "\n",
        "# í—íƒœì†Œë¶„ì„ê¸°ë¥¼ ì´ìš©í•´ ë‹¨ì–´ ë¬¶ìŒ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "komoran = Komoran()\n",
        "bow1 = komoran.nouns(sentence1)\n",
        "bow2 = komoran.nouns(sentence2)\n",
        "bow3 = komoran.nouns(sentence3)\n",
        "\n",
        "# ë‹¨ì–´ ë¬¶ìŒ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
        "bow = bow1 + bow2 + bow3\n",
        "\n",
        "# ë‹¨ì–´ ë¬¶ìŒì—ì„œ ì¤‘ë³µì œê±°í•´ ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•\n",
        "word_dics = []\n",
        "for token in bow:\n",
        "    if token not in word_dics:\n",
        "        word_dics.append(token)\n",
        "\n",
        "\n",
        "# ë¬¸ì¥ ë³„ ë‹¨ì–´ ë¬¸ì„œ í–‰ë ¬ ê³„ì‚°\n",
        "freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
        "freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
        "freq_list3 = make_term_doc_mat(bow3, word_dics)\n",
        "print(freq_list1)\n",
        "print(freq_list2)\n",
        "print(freq_list3)\n",
        "\n",
        "\n",
        "\n",
        "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "doc1 = np.array(make_vector(freq_list1))\n",
        "doc2 = np.array(make_vector(freq_list2))\n",
        "doc3 = np.array(make_vector(freq_list3))\n",
        "r1 = cos_sim(doc1, doc2)\n",
        "r2 = cos_sim(doc3, doc1)\n",
        "print(r1)\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl7F1SuSSE70",
        "outputId": "1139e1ba-8857-43d8-b7ff-b9d8ec8a0081"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'6ì›”': 1, 'ë‰´í„´': 1, 'ì„ ìƒë‹˜': 1, 'ì œì•ˆ': 1, 'íŠ¸ë¦¬ë‹ˆí‹°': 1, 'ì…í•™': 1, 'ëŒ€í•™êµ': 0, 'ë§›': 0, 'ë°¥': 0, 'ì„ ìƒ': 0, 'ë‹˜ê³¼ í•¨ê»˜': 0}\n",
            "{'6ì›”': 1, 'ë‰´í„´': 1, 'ì„ ìƒë‹˜': 1, 'ì œì•ˆ': 1, 'íŠ¸ë¦¬ë‹ˆí‹°': 0, 'ì…í•™': 1, 'ëŒ€í•™êµ': 1, 'ë§›': 0, 'ë°¥': 0, 'ì„ ìƒ': 0, 'ë‹˜ê³¼ í•¨ê»˜': 0}\n",
            "{'6ì›”': 0, 'ë‰´í„´': 1, 'ì„ ìƒë‹˜': 0, 'ì œì•ˆ': 0, 'íŠ¸ë¦¬ë‹ˆí‹°': 0, 'ì…í•™': 0, 'ëŒ€í•™êµ': 0, 'ë§›': 1, 'ë°¥': 1, 'ì„ ìƒ': 1, 'ë‹˜ê³¼ í•¨ê»˜': 1}\n"
          ]
        }
      ]
    }
  ]
}