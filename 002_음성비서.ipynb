{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeIg3A0qAuZANuFPmid60r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onleey/Machine-Learning_demo/blob/master/002_%EC%9D%8C%EC%84%B1%EB%B9%84%EC%84%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1W3Xd0eOJRx",
        "outputId": "842965be-f77f-4ced-8364-e5a9d71d7274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/001\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/001'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 텍스트를 음성 파일로 변환하는 gTTS 사용\n",
        "\n",
        "- 텍스트를 음성파일로 변환하는 TTS(Text-To-Speech)\n",
        "- TTS 기능을 구현하기 위해 gTTS라는 무료 TTS 패키지를 사용\n",
        "  - gTTS 공식 홈페이지 https://pypi.org/project/gTTS/\n",
        "  - 구글 클라우드의 유료 TTS 서비스 https://cloud.google.com/text-to-speech?hl=ko"
      ],
      "metadata": {
        "id": "fVPO_L6OOx0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.org/project/gTTS/\n",
        "!pip install gtts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iORwGntSPRBF",
        "outputId": "4f4b27bf-4a1b-4cbe-b122-ef16324bc79c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "tts = gTTS(text = '안녕하세요 음성비서 프로그램 실습중입니다.',lang='ko')\n",
        "tts.save('output.mp3')"
      ],
      "metadata": {
        "id": "6KAVYE9RO0NJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 음성 파일을  텍스트로 변환하는 Whisper API 사용\n",
        "\n",
        "- Whisper란  ChatGPT로 유명한 OpenAI에서 공개한 인공지능 모델로, 음성을 텍스트로 변환해 주는 Speech to Text(STT) 기술이다.\n",
        "- 약 68만 시간 분량의 방대한 데이터를 학습시켜 영어, 한국어를 포함한 다양한 언어를 인식할 수 있으며, 번역 및 언어 식별 기능이 있다.\n",
        "- Whisper 모델은 오픈소스로 공개돼 있으며 구체적인 모델의 구조는 공식 홈페이지에서 확인할 수 있다.\n",
        " -  https://openai.com/research/whisper\n",
        "- Whisper 가격\n",
        " - https://openai.com/pricing"
      ],
      "metadata": {
        "id": "tDzLMrYnPoZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DGYF1pePpT9",
        "outputId": "305aec4b-50e9-418d-fd21-83e92a5bf853"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/77.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "#api 키 입력\n",
        "openai.api_key= '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'\n",
        "\n",
        "#녹음파일열기\n",
        "audio_file= open('output.mp3','rb')\n",
        "#whisper 모델에 음원파일 전달하기\n",
        "transcript= openai.Audio.transcribe('whisper-1', audio_file)\n",
        "print(dir(transcript))\n",
        "#결과보기\n",
        "print(transcript['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOrOxKSAQAXM",
        "outputId": "e8b79cdc-6f3b-4715-b341-16b4424608b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__class_getitem__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_previous', '_response_ms', '_retrieve_params', 'api_base', 'api_base_override', 'api_key', 'api_type', 'api_version', 'arequest', 'clear', 'construct_from', 'copy', 'engine', 'fromkeys', 'get', 'items', 'keys', 'openai_id', 'organization', 'pop', 'popitem', 'refresh_from', 'request', 'response_ms', 'setdefault', 'to_dict', 'to_dict_recursive', 'typed_api_type', 'update', 'values']\n",
            "안녕하세요 음성비서 프로그램 실습 중입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|기능|Streamlit|Django|Flask|\n",
        "|---|---|---|---|\n",
        "|데이터 과학 및 머신 러닝에 특화| ㅇ | X | X |\n",
        "|사용의 용이성|높음(최소한의 코딩 필요) | 중간(많은 학습 필요)|중간(웹 개발 이해 필요)|\n",
        "|웹 개발 지식 필요여부| X | ㅇ | ㅇ |\n",
        "\n",
        "\n",
        "- 스트림릿 기본 함수\n",
        "  - st.title( ) : 앱에 제목을 생성한다.\n",
        "  - st.header( ) : 앱에 헤더를 생성한다.\n",
        "  - st.subheader( ) : 앱에 서브헤더를 생성한다.\n",
        "  - st.text( ) : 앱에 일반 텍스트를 생성한다.\n",
        "  - st.write( ) : 앱에 텍스트나 데이터를 생성한다. 이 함수를 다용도로 사용할 수 있으며 텍스트, 데이터 프레임 또는 플롯을 표시할 수 있다."
      ],
      "metadata": {
        "id": "ebqmwOxYVC4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSxnRsQvVEAM",
        "outputId": "8c802b60-dcf6-49cb-b6d7-31b60b39a0ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, importlib-metadata, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 importlib-metadata-6.11.0 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.29.0 validators-0.22.0 watchdog-3.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_example.py\n",
        "import streamlit as streamlit\n",
        "\n",
        "st.title('나의 첫번째 streamlit 앱')\n",
        "\n",
        "st.header('streamlit에 오신것을 환영합니다')\n",
        "st.subheader('웹앱을 만들기위한 강력하고 사용하기 쉬운 라이브러리')\n",
        "\n",
        "st.text('이것은 일반텍스트입니다')\n",
        "\n",
        "st.write('write()함수를 사용하여 텍스트, 데이터 또는 플롯을 표시할 수도 있습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x4Me_-bVgvc",
        "outputId": "af793b4e-46ef-4dad-cbe0-8c71aeb131e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrok은 외부에서 로컬에 접속할수있게 도와주는 터널링 프로그램이다\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "!streamlit run streamlit_example.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk52Z9OnWpCN",
        "outputId": "99e38eaa-5de2-4272-c98a-e4ffeac37118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://1679-34-172-215-218.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.172.215.218:5000\u001b[0m\n",
            "\u001b[0m\n",
            "2023-12-28 00:41:00.434 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 534, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/drive/MyDrive/001/streamlit_example.py\", line 3, in <module>\n",
            "    st.title('나의 첫번째 streamlit 앱')\n",
            "NameError: name 'st' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-28T00:41:43+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-cf707911-361f-4983-90b3-39f82dd8b906 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2023-12-28T00:41:43+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-cf707911-361f-4983-90b3-39f82dd8b906 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 스트림릿으로 음성 비서 프로그램의 UI 만들기\n",
        "\n",
        "- 기본 설명 영역 : 제목과 기본 정보를 설명하는 영역이다.\n",
        "- 옵션 선택 영역 : OpenAI API 키를 입력받고, GPT 모델을 선택하기 위한 라디오 버튼과 초기화 버튼이 있는 영역이다.\n",
        "- 기능 구현 영역 : 음성을 녹음하고, 녹음한 음성을 재생하는 기능과 이를 채팅창 화면으로 보여주는 영역이다."
      ],
      "metadata": {
        "id": "aKYCqyf4ZrTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "### 기본정보입력####\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "### 메인함수 ####\n",
        "def main():\n",
        "\n",
        "    #기본설정\n",
        "    st.set_page_config(\n",
        "       page_title= '음성비서프로그램',\n",
        "       layout = 'wide'\n",
        "    )\n",
        "\n",
        "\n",
        "    #제목\n",
        "    st.header ('음성비서프로그램')\n",
        "\n",
        "    #구분선\n",
        "\n",
        "    st.markdown('------------')\n",
        "\n",
        "\n",
        "    #기본설명\n",
        "    with st.expander ('음성비서 프로그램에 관하여', expanded=True):\n",
        "      st.write(\n",
        "         '''\n",
        "\n",
        "         -음성비서 프로그램의 UI는 스트림릿을 활용했다\n",
        "         -STT(Speech-To-Text)는 OpenAI의 Whister AI를 활용했다.\n",
        "\n",
        "      )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjI-XmRNW9W6",
        "outputId": "a5632153-cfb0-47f9-e791-ce2d237df65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHfEUi6cFqf",
        "outputId": "59f46c00-2ac1-4437-8c7e-ca6e077abc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://6b97-34-172-215-218.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.172.215.218:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵션선택 구현하기"
      ],
      "metadata": {
        "id": "46B_b3JNcb4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "### 기본정보입력####\n",
        "\n",
        "import streamlit as st\n",
        "import openai  #openai 패키지 추가\n",
        "\n",
        "### 메인함수 ####\n",
        "def main():\n",
        "\n",
        "    #기본설정\n",
        "    st.set_page_config(\n",
        "       page_title= '음성비서프로그램',\n",
        "       layout = 'wide'\n",
        "    )\n",
        "\n",
        "\n",
        "    #제목\n",
        "    st.header ('음성비서프로그램')\n",
        "\n",
        "    #구분선\n",
        "\n",
        "    st.markdown('------------')\n",
        "\n",
        "\n",
        "    #기본설명\n",
        "    with st.expander ('음성비서 프로그램에 관하여', expanded=True):\n",
        "      st.write(\n",
        "         '''\n",
        "\n",
        "         -음성비서 프로그램의 UI는 스트림릿을 활용했다\n",
        "         -STT(Speech-To-Text)는 OpenAI의 Whister AI를 활용했다.\n",
        "        '''\n",
        "      )\n",
        "############################################################################\n",
        "    # 사이드바 설명\n",
        "    with st.sidebar:\n",
        "      #open api api 키 입력받기\n",
        "      openai.api_key = st.text_input(label='OPENAPI API 키',placeholder= 'Enter your API Key', value='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',type ='password')\n",
        "\n",
        "      st.markdown('------')\n",
        "\n",
        "\n",
        "      #GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "      model = st.radio(label ='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "      st.markdown('-------')\n",
        "\n",
        "\n",
        "\n",
        "      #리셋버튼생성\n",
        "      if st.button(label = '초기화'):\n",
        "        pass\n",
        "#################################################################################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYXCBnDtcdfV",
        "outputId": "3a36beba-48f8-4355-93be-eaeeebbe1678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0o1YzrJd_h3",
        "outputId": "ff624694-e0ea-48e3-c327-20b4846ec490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://5ee1-34-172-215-218.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.172.215.218:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기능 구현 영역 구현하기"
      ],
      "metadata": {
        "id": "9XySUvXm9Tfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 스트림릿의 상태를 저장하기 위한 session_state 함수\n",
        "\n",
        "- 스트림릿 프로그램은 사용자가 버튼을 누르거나 텍스트를 입력할 때마다 코드가 처음부터 끝까지 재실행되는데, 이 과정에서 내부의 모든 변수가 초기화 된다.\n",
        "- 예를 들어, ChatGPT에게 처음 질문을 한 후 이어서 두 번째 질문을 하기 위해 녹음 버튼을 한 번 더 클릭하면 프로그램이 처음부터 다시 실행된다.\n",
        "- 이로 인해 변수들이 모두 초기화되고, 첫번째 질문의 기록이 사라지는 문제가 발생한다. 이러한 문제를 해결하는 방법이 session_state이다.\n",
        "- st.session_state는 스트림릿에서 사용하는 저장 공간으로, session_state을 이용하면 프로그램을 재실행하더라도 정보가 초기화되지 않고 계속 유지된다.\n",
        "- session_state는 파이썬의 딕셔너리 형태로 여러 개의 정보를 저장할 수 있다."
      ],
      "metadata": {
        "id": "-euVY2X3_1G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "상태를 저장하기 위한 session_state 추가  \n",
        "\n",
        "- st.session_state['chat'] : 사용자와 음성 비서의 대화 내용을 저장하여 채팅창에 표시하는데 사용한다.\n",
        "- st.session_state['message'] : GPT API에 입력(input)으로 전달할 프롬프트 양식을 저장한다. 이전 질문과 답변 모두 차례로 누적하여 저장한다.\n",
        "- st.session_state['check_audio'] : 프로그램이 다시 실행될 때 마다 이전 녹음 파일의 정보가 버퍼에 남아서 실행되는 것을 방지하기 위해 사용자가 녹음한 음원을 리스트 형태로 저장한다. 새로운 녹음이 들어오면 저장해 둔 음원과 비교하여 새로운 녹음인지 판단한다."
      ],
      "metadata": {
        "id": "uudoEWXI_45F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "### 기본정보입력####\n",
        "\n",
        "import streamlit as st\n",
        "import openai  #openai 패키지 추가\n",
        "\n",
        "### 메인함수 ####\n",
        "def main():\n",
        "\n",
        "    #기본설정\n",
        "    st.set_page_config(\n",
        "       page_title= '음성비서프로그램',\n",
        "       layout = 'wide'\n",
        "    )\n",
        "\n",
        "\n",
        "    #제목\n",
        "    st.header ('음성비서프로그램')\n",
        "\n",
        "    #구분선\n",
        "\n",
        "    st.markdown('------------')\n",
        "\n",
        "\n",
        "    #기본설명\n",
        "    with st.expander ('음성비서 프로그램에 관하여', expanded=True):\n",
        "      st.write(\n",
        "         '''\n",
        "\n",
        "         -음성비서 프로그램의 UI는 스트림릿을 활용했다\n",
        "         -STT(Speech-To-Text)는 OpenAI의 Whister AI를 활용했다.\n",
        "        '''\n",
        "      )\n",
        "############################################################################\n",
        "    # 사이드바 설명\n",
        "    with st.sidebar:\n",
        "      #open api api 키 입력받기\n",
        "      openai.api_key = st.text_input(label='OPENAPI API 키',placeholder= 'Enter your API Key', value='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',type ='password')\n",
        "\n",
        "      st.markdown('------')\n",
        "\n",
        "\n",
        "      #GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "      model = st.radio(label ='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "      st.markdown('-------')\n",
        "\n",
        "\n",
        "\n",
        "      #리셋버튼생성\n",
        "      if st.button(label = '초기화'):\n",
        "        pass\n",
        "##########################################################################################\n",
        "      # 기능구현공간\n",
        "      # 기능 구현 영역을 두 개의 영역으로 분할한다. 분할한 각 영역의 이름은 col1, col2로 구분한다.\n",
        "    col1,col2 = st.columns(2)\n",
        "    with col1:\n",
        "        #왼쪽영역 작성\n",
        "      st.subheader('질문하기')\n",
        "\n",
        "\n",
        "    with col2:\n",
        "         #오른쪽 영역 작성\n",
        "      st.subheader ('질문/답변')\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJGLZR8h9WY-",
        "outputId": "39a3a5dd-771f-4971-f49d-4bc985c85515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obz-PVRP_E_3",
        "outputId": "c5142bfd-ba4f-4b21-f652-e918f74d73c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://45d6-34-172-215-218.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.172.215.218:5000\u001b[0m\n",
            "\u001b[0m\n",
            "2023-12-28 01:16:39.400 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 534, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/drive/MyDrive/001/voicebot.py\", line 78, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/001/voicebot.py\", line 62, in main\n",
            "    with col2:\n",
            "NameError: name 'col2' is not defined\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 스트림릿의 상태를 저장하기 위한 session_state 함수\n",
        "스트림릿 프로그램은 사용자가 버튼을 누르거나 텍스트를 입력할 때마다 코드가 처음부터 끝까지 재실행되는데, 이 과정에서 내부의 모든 변수가 초기화 된다.\n",
        "예를 들어, ChatGPT에게 처음 질문을 한 후 이어서 두 번째 질문을 하기 위해 녹음 버튼을 한 번 더 클릭하면 프로그램이 처음부터 다시 실행된다.\n",
        "이로 인해 변수들이 모두 초기화되고, 첫번째 질문의 기록이 사라지는 문제가 발생한다. 이러한 문제를 해결하는 방법이 session_state이다.\n",
        "st.session_state는 스트림릿에서 사용하는 저장 공간으로, session_state을 이용하면 프로그램을 재실행하더라도 정보가 초기화되지 않고 계속 유지된다.\n",
        "session_state는 파이썬의 딕셔너리 형태로 여러 개의 정보를 저장할 수 있다.\n",
        "\n",
        "상태를 저장하기 위한 session_state 추가  \n",
        "\n",
        "- st.session_state['chat'] : 사용자와 음성 비서의 대화 내용을 저장하여 채팅창에 표시하는데 사용한다.\n",
        "- st.session_state['message'] : GPT API에 입력(input)으로 전달할 프롬프트 양식을 저장한다. 이전 질문과 답변 모두 차례로 누적하여 저장한다.\n",
        "- st.session_state['check_audio'] : 프로그램이 다시 실행될 때 마다 이전 녹음 파일의 정보가 버퍼에 남아서 실행되는 것을 방지하기 위해 사용자가 녹음한 음원을 리스트 형태로 저장한다. 새로운 녹음이 들어오면 저장해 둔 음원과 비교하여 새로운 녹음인지 판단한다."
      ],
      "metadata": {
        "id": "0-Brzeqk_z6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "### 기본정보입력####\n",
        "\n",
        "import streamlit as st\n",
        "import openai  #openai 패키지 추가\n",
        "\n",
        "### 메인함수 ####\n",
        "def main():\n",
        "\n",
        "    #기본설정\n",
        "    st.set_page_config(\n",
        "       page_title= '음성비서프로그램',\n",
        "       layout = 'wide'\n",
        "    )\n",
        "###############################\n",
        "## 2. 상태를 저장하기 위한 session_state 추가\n",
        "## 2-1 session state 초기화\n",
        "## 2-2 리셋코드\n",
        "######################################\n",
        "# 2-1 session state 초기화\n",
        "    if 'chat' not in st.session_state:\n",
        "      st.session_state['chat']=[]\n",
        "\n",
        "    if'messages' not in st.session_state:\n",
        "      st.session_state['messages'] = [{'role': 'system',\n",
        "          'content': 'you are a thoughtful assistant. Respond to all input in 25 word and answer in korea'}]\n",
        "\n",
        "    if 'check_reset' not in st.session_state:\n",
        "      st.session_state['check_reset'] =False\n",
        "####################################################\n",
        "\n",
        "    #제목\n",
        "    st.header ('음성비서프로그램')\n",
        "\n",
        "    #구분선\n",
        "\n",
        "    st.markdown('------------')\n",
        "\n",
        "\n",
        "    #기본설명\n",
        "    with st.expander ('음성비서 프로그램에 관하여', expanded=True):\n",
        "      st.write(\n",
        "         '''\n",
        "\n",
        "         -음성비서 프로그램의 UI는 스트림릿을 활용했다\n",
        "         -STT(Speech-To-Text)는 OpenAI의 Whister AI를 활용했다.\n",
        "        '''\n",
        "      )\n",
        "############################################################################\n",
        "    # 사이드바 설명\n",
        "    with st.sidebar:\n",
        "      #open api api 키 입력받기\n",
        "      openai.api_key = st.text_input(label='OPENAPI API 키',placeholder= 'Enter your API Key', value='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',type ='password')\n",
        "\n",
        "      st.markdown('------')\n",
        "\n",
        "\n",
        "      #GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "      model = st.radio(label ='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "      st.markdown('-------')\n",
        "\n",
        "\n",
        "\n",
        "      #리셋버튼생성\n",
        "      if st.button(label = '초기화'):\n",
        "        ##################################\n",
        "        #2-2 리셋코드\n",
        "        ###################################\n",
        "        # 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat']과\n",
        "        #st.session_state['messages']의 session_state를 초기화 한다.\n",
        "\n",
        "\n",
        "        st.session_state['chat']=[]\n",
        "        st.session_state['messages'] = [{'role':'system','content':'yyou are a thoughtful assistant. Respond to all input in 25 word and answer in korea '}]\n",
        "        st.session_state['check_reset'] = True\n",
        "##########################################################################################\n",
        "      # 기능구현공간\n",
        "      # 기능 구현 영역을 두 개의 영역으로 분할한다. 분할한 각 영역의 이름은 col1, col2로 구분한다.\n",
        "    col1,col2 = st.columns(2)\n",
        "    with col1:\n",
        "        #왼쪽영역 작성\n",
        "      st.subheader('질문하기')\n",
        "\n",
        "\n",
        "    with col2:\n",
        "         #오른쪽 영역 작성\n",
        "      st.subheader ('질문/답변')\n",
        "\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM6Qz11KAdgn",
        "outputId": "bb5a9533-c6b8-41b0-f706-3683e8af3c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dep6sUMUEnMm",
        "outputId": "f7b46b20-7513-41b1-a004-ac8182142b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://945e-34-172-215-218.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.172.215.218:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "- 스트림릿의 기본 패키지에는 음성을 녹음하기 위한 기능이 없으므로 streamlit-audiorecorder라는  새로운 패키지를 설치한다.\n",
        "- streamlit-audiorecorder를 활용하면 스트림릿에서 음성 녹음 버튼을 생성하고, 녹음 결과를 파일로 저장할 수 있다."
      ],
      "metadata": {
        "id": "CZ8m2dXfGiZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit-audiorecorder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7CrL2ixHvuZ",
        "outputId": "9ea9dca1-6cf6-4894-c330-d05fdd9c9724"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-audiorecorder\n",
            "  Downloading streamlit_audiorecorder-0.0.4-py3-none-any.whl (447 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/447.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/447.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m440.3/447.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-audiorecorder) (1.29.0)\n",
            "Collecting pydub>=0.24 (from streamlit-audiorecorder)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.11.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-audiorecorder) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-audiorecorder) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-audiorecorder) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (0.1.2)\n",
            "Installing collected packages: pydub, streamlit-audiorecorder\n",
            "Successfully installed pydub-0.25.1 streamlit-audiorecorder-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiorecorder import audiorecorder\n",
        "print(dir(audiorecorder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWesfWHvIaf3",
        "outputId": "5b4fc760-2374-43ee-cf66-533d9694c6dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "##### 기본 정보 입력 #####\n",
        "import streamlit as st\n",
        "\n",
        "# OpenAI 패키기 추가\n",
        "import openai\n",
        "\n",
        "# audiorecorder 패키지 추가\n",
        "from audiorecorder import audiorecorder\n",
        "#파일 삭제를 위한 패키지 추가\n",
        "import os\n",
        "#시간 정보를 위핸 패키지 추가\n",
        "from datetime import datetime\n",
        "\n",
        "#### 메인 함수 ####\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "      page_title='음성 비서 프로그램',\n",
        "      layout='wide'\n",
        "  )\n",
        "\n",
        "  ##################################################################\n",
        "  ## 2. 상태를 저장하기 위한 session_state 추가\n",
        "  ## 2-1 session state 초기화\n",
        "  ## 2-2 리셋 코드\n",
        "  ###################################################################\n",
        "  # 2-1 session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        "  ######################################################################\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        '''\n",
        "    )\n",
        "\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='OPENAPI API  키', placeholder='Enter Your API Key', value='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', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      ########################################################################\n",
        "      # 2-2 리셋 코드\n",
        "      #######################################################################\n",
        "      # 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat']과\n",
        "      # st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "      st.session_state[\"chat\"] = []\n",
        "      st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "      st.session_state[\"check_reset\"] = True\n",
        "      #######################################################################\n",
        "\n",
        "\n",
        "  # 기능 구현 공간\n",
        "\n",
        "  # 기능 구현 영역을 두 개의 영역으로 분할한다. 분할한 각 영역의 이름은 col1, col2로 지정한다.\n",
        "  col1, col2  = st.columns(2)\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    ###########################################################################\n",
        "    ### 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "    ### 3-1 사용자의 음성 입력받기및 재생 버튼생성하기\n",
        "    ###########################################################################\n",
        "    #  음성 녹음 아이콘 추가\n",
        "     # audiorecorder(start, stop, pause)\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\")\n",
        "\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      # 음성 재생\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ###########################################################################\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwX3jaGeHul-",
        "outputId": "e76bf353-f8c9-4766-f9da-8494ce86ec00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06YBGmUJKf1-",
        "outputId": "1bdaa73c-8346-484f-b3c3-b466499ffeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://e61b-34-73-75-237.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.73.75.237:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "##### 기본 정보 입력 #####\n",
        "import streamlit as st\n",
        "\n",
        "# OpenAI 패키기 추가\n",
        "import openai\n",
        "\n",
        "# audiorecorder 패키지 추가\n",
        "from audiorecorder import audiorecorder\n",
        "#파일 삭제를 위한 패키지 추가\n",
        "import os\n",
        "#시간 정보를 위핸 패키지 추가\n",
        "from datetime import datetime\n",
        "\n",
        "################################\n",
        "##### 기능구현함수 #######\n",
        "def STT(audio):\n",
        "    #파일 저장\n",
        "    filename= 'input.mp3'\n",
        "    audio.export(filename, format='mp3')\n",
        "\n",
        "    #음원 파일 열기\n",
        "    audio_file = open(filename, 'rb')\n",
        "    #Whisper 모델을 활용해 텍스트 얻기\n",
        "    transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
        "    audio_file.close()\n",
        "\n",
        "    #gTTS를 위한 자동생성\n",
        "    filename='output.mp3'\n",
        "    tts=gTTS(text=response, lang='ko')\n",
        "    tts.save(filename)\n",
        "\n",
        "    #음원파일 자동생성\n",
        "    with open(filename,'rb')as f:\n",
        "        data = f.read()\n",
        "        b64 = base64.b64encode(data).decode()\n",
        "        md = f'''\n",
        "            <audio autoplay='True'>\n",
        "            <source src='data:audio/mp3;base64,{b64}' type='audio/mp3'>\n",
        "            '''\n",
        "\n",
        "        st.markdawn(md,unsafe_allow_html=True,)\n",
        "\n",
        "    #파일삭제\n",
        "    os.remove(filename)\n",
        "    return transcript['text']\n",
        "\n",
        "#### 메인 함수 ####\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "      page_title='음성 비서 프로그램',\n",
        "      layout='wide'\n",
        "  )\n",
        "\n",
        "  ##################################################################\n",
        "  ## 2. 상태를 저장하기 위한 session_state 추가\n",
        "  ## 2-1 session state 초기화\n",
        "  ## 2-2 리셋 코드\n",
        "  ###################################################################\n",
        "  # 2-1 session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        "  ######################################################################\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        '''\n",
        "    )\n",
        "\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='OPENAPI API  키', placeholder='Enter Your API Key', value='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', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      ########################################################################\n",
        "      # 2-2 리셋 코드\n",
        "      #######################################################################\n",
        "      # 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat']과\n",
        "      # st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "      st.session_state[\"chat\"] = []\n",
        "      st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "      st.session_state[\"check_reset\"] = True\n",
        "      #######################################################################\n",
        "\n",
        "\n",
        "  # 기능 구현 공간\n",
        "\n",
        "  # 기능 구현 영역을 두 개의 영역으로 분할한다. 분할한 각 영역의 이름은 col1, col2로 지정한다.\n",
        "  col1, col2  = st.columns(2)\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    ###########################################################################\n",
        "    ### 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "    ### 3-1 사용자의 음성 입력받기및 재생 버튼생성하기\n",
        "    ###########################################################################\n",
        "    #  음성 녹음 아이콘 추가\n",
        "     # audiorecorder(start, stop, pause)\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\")\n",
        "\n",
        "\n",
        "  if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "     # 음성 재생\n",
        "    st.audio(audio.export().read())\n",
        "\n",
        "    #음원파일에서 텍스트 추출\n",
        "    question = STT(audio)\n",
        "\n",
        "    # 채팅을 시각화하기위해 질문 내용 저장\n",
        "    now = datetime.now().strftime('%H:%M')\n",
        "    st.session_state['chat']= st.session_state['chat']+[('user',now, question)]\n",
        "    #GPT 모델에 넣을 프롬프트를 위해 질문 내용 저장\n",
        "    st.session_state['message'] = st.session_state['messages']+[{'role':'user','content':question}]\n",
        "    ###########################################################################\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "\n",
        "    ## 5-2 대화내용을 채팅형식으로 시각화 하기\n",
        "    ####################################################\n",
        "            # 채팅 형식으로 시각화 하기\n",
        "            for sender, time, message in st.session_state[\"chat\"]:\n",
        "                if sender == \"user\":\n",
        "                    st.write(f'<div style=\"display:flex;align-items:center;\"><div style=\"background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                    st.write(\"\")\n",
        "                else:\n",
        "                    st.write(f'<div style=\"display:flex;align-items:center;justify-content:flex-end;\"><div style=\"background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                    st.write(\"\")\n",
        "            #gTTS를 활용하여 음성 파일 생성 및 재생\n",
        "             TTS(response)\n",
        "    else:\n",
        "      st.session_state['check_reset']=False\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk78RuvAWPe-",
        "outputId": "14a191e8-d7f1-4ca6-d767-8a2765df3285"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qaBP88dW_nO",
        "outputId": "ecffa962-cd96-4a84-f5f5-39f4c0824bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://740f-34-73-75-237.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.73.75.237:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "\n",
        "##### 기본 정보 입력 #####\n",
        "import streamlit as st\n",
        "\n",
        "# audiorecorder 패키지 추가\n",
        "from audiorecorder import audiorecorder\n",
        "\n",
        "# OpenAI 패키지 추가\n",
        "import openai\n",
        "# 파일 삭제를 위한 패키지 추가\n",
        "import os\n",
        "# 시간 정보를 위한 패키지 추가\n",
        "from datetime import datetime\n",
        "\n",
        "# TTS 패키지 추가\n",
        "from gtts import gTTS\n",
        "# 음원파일 재생을 위한 패키지 추가\n",
        "import base64\n",
        "\n",
        "#################################\n",
        "##### 기능 구현 함수 #####\n",
        "def STT(audio):\n",
        "    # 파일 저장\n",
        "    filename='input.mp3'\n",
        "    audio.export(filename, format=\"mp3\")\n",
        "    # 음원 파일 열기\n",
        "    audio_file = open(filename, \"rb\")\n",
        "    #Whisper 모델을 활용해 텍스트 얻기\n",
        "    transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "    audio_file.close()\n",
        "    # 파일 삭제\n",
        "    os.remove(filename)\n",
        "    return transcript[\"text\"]\n",
        "\n",
        "def ask_gpt(prompt, model):\n",
        "    response = openai.ChatCompletion.create(model=model, messages=prompt)\n",
        "    system_message = response[\"choices\"][0][\"message\"]\n",
        "    return system_message[\"content\"]\n",
        "\n",
        "def TTS(response):\n",
        "    # gTTS 를 활용하여 음성 파일 생성\n",
        "    filename = \"output.mp3\"\n",
        "    tts = gTTS(text=response,lang=\"ko\")\n",
        "    tts.save(filename)\n",
        "\n",
        "    # 음원 파일 자동 재성\n",
        "    with open(filename, \"rb\") as f:\n",
        "        data = f.read()\n",
        "        b64 = base64.b64encode(data).decode()\n",
        "        md = f\"\"\"\n",
        "            <audio autoplay=\"True\">\n",
        "            <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
        "            </audio>\n",
        "            \"\"\"\n",
        "        st.markdown(md,unsafe_allow_html=True,)\n",
        "    # 파일 삭제\n",
        "    os.remove(filename)\n",
        "\n",
        "#### 메인 함수 ####\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "      page_title='음성 비서 프로그램',\n",
        "      layout='wide'\n",
        "  )\n",
        "\n",
        "  ##################################################################\n",
        "  ## 상태를 저장하기 위한 session_state 추가\n",
        "  ###################################################################\n",
        "  # session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        "  ######################################################################\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "        '''\n",
        "        - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "        - STT(Speech-To-Text)는 OpenAI의 Whisper AI를 활용했다.\n",
        "        '''\n",
        "    )\n",
        "\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    #openai.api_key = st.text_input(label='OPENAPI API  키', placeholder='Enter Your API Key', value='', type='password')\n",
        "    openai.api_key = st.text_input(label='OPENAPI API  키', placeholder='Enter Your API Key', value='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', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      ########################################################################\n",
        "      # 리셋 코드\n",
        "      #######################################################################\n",
        "      # 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat']과\n",
        "      # st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "      st.session_state[\"chat\"] = []\n",
        "      st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "      st.session_state[\"check_reset\"] = True\n",
        "      #######################################################################\n",
        "\n",
        "\n",
        "  # 기능 구현 공간\n",
        "\n",
        "  # 기능 구현 영역을 두 개의 영역으로 분할한다. 분할한 각 영역의 이름은 col1, col2로 지정한다.\n",
        "  col1, col2  = st.columns(2)\n",
        "  with col1:\n",
        "    # 왼쪽 영역 작성\n",
        "    st.subheader('질문하기')\n",
        "    #########################################################################\n",
        "    ### 3-1 사용자의 음성 입력받기및 재생 버튼생성하기\n",
        "    ###########################################################################\n",
        "    #  음성 녹음 아이콘 추가\n",
        "     # audiorecorder(start, stop, pause)\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\")\n",
        "\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      # 음성 재생\n",
        "      st.audio(audio.export().read())\n",
        "      # 음원 파일에서 텍스트 추출\n",
        "      question = STT(audio)\n",
        "\n",
        "      # 채팅을 시각화하기 위해 질문 내용 저장\n",
        "      now = datetime.now().strftime(\"%H:%M\")\n",
        "      st.session_state[\"chat\"] = st.session_state[\"chat\"]+ [(\"user\",now, question)]\n",
        "      # GPT 모델에 넣을 프롬프트를 위해 질문 내용 저장\n",
        "      st.session_state[\"messages\"] = st.session_state[\"messages\"]+ [{\"role\": \"user\", \"content\": question}]\n",
        "    ###########################################################################\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 작성\n",
        "    st.subheader('질문/답변')\n",
        "    ########################################################################\n",
        "    ## 5. ChatGPT API로 질문하고 답변구하기\n",
        "    #####################################################################\n",
        "    ## 5.1 ChatGPT API를 활용하여 답변 구하기\n",
        "    #####################################\n",
        "    if  (audio.duration_seconds > 0)  and (st.session_state[\"check_reset\"]==False):\n",
        "            #ChatGPT에게 답변 얻기\n",
        "            response = ask_gpt(st.session_state[\"messages\"], model)\n",
        "\n",
        "            # GPT 모델에 넣을 프롬프트를 위해 답변 내용 저장\n",
        "            st.session_state[\"messages\"] = st.session_state[\"messages\"]+ [{\"role\": \"system\", \"content\": response}]\n",
        "\n",
        "            # 채팅 시각화를 위한 답변 내용 저장\n",
        "            now = datetime.now().strftime(\"%H:%M\")\n",
        "            st.session_state[\"chat\"] = st.session_state[\"chat\"]+ [(\"bot\",now, response)]\n",
        "      #########################################################\n",
        "      ## 5-2 대화 내용을 채팅 형식으로 시각화 하기\n",
        "      #########################################################\n",
        "            # 채팅 형식으로 시각화 하기\n",
        "            for sender, time, message in st.session_state[\"chat\"]:\n",
        "                if sender == \"user\":\n",
        "                    st.write(f'<div style=\"display:flex;align-items:center;\"><div style=\"background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                    st.write(\"\")\n",
        "                else:\n",
        "                    st.write(f'<div style=\"display:flex;align-items:center;justify-content:flex-end;\"><div style=\"background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "                    st.write(\"\")\n",
        "\n",
        "            # gTTS 를 활용하여 음성 파일 생성 및 재생\n",
        "            TTS(response)\n",
        "    else:\n",
        "      st.session_state[\"check_reset\"] = False\n",
        "    ##############################################################################\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSae9F-4Rc2o",
        "outputId": "77497bba-41d7-4b48-dbbf-99c949fb8b23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "port=5000\n",
        "ngrok.set_auth_token('2ZQFEUtWZGS9UAUus9DuaIUSOd6_37FdNRLA4rwH5mRMBsGkH')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "\n",
        "\n",
        "#!streamlit run/content/drive/Mydrive/001/voicebot.py\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAxwpJ7sSVSA",
        "outputId": "d96c1d4f-6d6f-4a95-b64d-788a5e0806e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://0757-104-196-177-111.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.196.177.111:5000\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-28T07:25:26+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-6ff1b231-8d16-4909-8789-78085faf7532 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}